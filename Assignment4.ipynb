{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eO_bVRH4vphHi6V4Oap3ioPYBzDTOQsS","timestamp":1678969871390}],"authorship_tag":"ABX9TyME3Db3Nfz3CXb261PWdjjV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"과제5 CNN기반 영상분류문제\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1Py2GvZc1GwqNbrR4fuQrHFy6zBEdF1xF\n","\"\"\"\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten,Dense\n","from tensorflow.keras.optimizers import Adam\n","import os\n","from tensorflow.keras.datasets import cifar10\n","from sklearn.model_selection import train_test_split\n","import random\n","\n","(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n","x_train=x_train.astype(np.float32)/255.0\n","y_train=tf.keras.utils.to_categorical(y_train,10)\n","\n","x_test=x_test.astype(np.float32)/255.0\n","y_test=tf.keras.utils.to_categorical(y_test,10)\n","\n","x_val, _, y_val,_ = train_test_split(x_test, y_test, test_size=0.6, random_state=1)\n","\n","input_shape = x_train.shape[1:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPjAtRIRjtgw","executionInfo":{"status":"ok","timestamp":1682227387427,"user_tz":-540,"elapsed":14893,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"550d0238-aa4d-42af-9d5c-6f1d81afb43d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","source":["#동일조건 유지해야 하는 변수(두 모델 모두 동일하게 적용해야 함)\n","g_epoch = 70\n","g_batch = 64\n","\n","#중요 : 아래함수 변경 불가!\n","def reset_random_seeds():\n","   os.environ['PYTHONHASHSEED']=str(1)\n","   tf.random.set_seed(1)\n","   np.random.seed(1)\n","   random.seed(1)\n","   os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","reset_random_seeds() #필수\n","   \n","print(\"reduced train/val size:\", len(x_train), len(x_val), \"input shape:\", input_shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCxhnS9dj5K1","executionInfo":{"status":"ok","timestamp":1682227408014,"user_tz":-540,"elapsed":311,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"01836c93-b699-4cc0-bad4-0c06e36d2089"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["reduced train/val size: 50000 4000 input shape: (32, 32, 3)\n"]}]},{"cell_type":"code","source":["# to make this notebook's output stable across runs\n","\n","tf.__version__\n","\n","from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n","\n","cnn=Sequential()\n","cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)))\n","cnn.add(MaxPooling2D(pool_size=(2,2)))\n","cnn.add(Dropout(0.25))\n","cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2,2)))\n","cnn.add(Dropout(0.25))\n","cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n","cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2,2)))\n","cnn.add(Flatten())\n","cnn.add(Dense(1000,activation='relu'))\n","cnn.add(Dropout(0.5))\n","cnn.add(Dense(10,activation='softmax'))\n","\n","cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n","cnn.summary()\n","\n","hist=cnn.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n","             validation_data=(x_val,y_val), verbose=1)\n","\n","g_org_res=cnn.evaluate(x_test,y_test,verbose=0)\n","print(\"Baseline 정확률은\",g_org_res[1]*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiodoNBzj90x","executionInfo":{"status":"ok","timestamp":1682229008309,"user_tz":-540,"elapsed":609895,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"3bb547e0-2bc8-4e41-fb88-859a20e6b27f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 30, 30, 64)        1792      \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 15, 15, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         (None, 15, 15, 64)        0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 15, 15, 128)       73856     \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 7, 7, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_4 (Dropout)         (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 7, 7, 256)         295168    \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 7, 7, 256)         590080    \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 3, 3, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 2304)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1000)              2305000   \n","                                                                 \n"," dropout_5 (Dropout)         (None, 1000)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                10010     \n","                                                                 \n","=================================================================\n","Total params: 3,275,906\n","Trainable params: 3,275,906\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/70\n","782/782 [==============================] - 11s 12ms/step - loss: 2.0993 - accuracy: 0.2185 - val_loss: 1.8936 - val_accuracy: 0.3198\n","Epoch 2/70\n","782/782 [==============================] - 8s 11ms/step - loss: 1.7866 - accuracy: 0.3509 - val_loss: 1.7263 - val_accuracy: 0.3755\n","Epoch 3/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.6712 - accuracy: 0.3914 - val_loss: 1.6270 - val_accuracy: 0.4008\n","Epoch 4/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.5897 - accuracy: 0.4207 - val_loss: 1.5907 - val_accuracy: 0.4180\n","Epoch 5/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.5302 - accuracy: 0.4428 - val_loss: 1.5216 - val_accuracy: 0.4495\n","Epoch 6/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.4807 - accuracy: 0.4598 - val_loss: 1.5002 - val_accuracy: 0.4665\n","Epoch 7/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.4378 - accuracy: 0.4799 - val_loss: 1.4332 - val_accuracy: 0.4895\n","Epoch 8/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.4007 - accuracy: 0.4933 - val_loss: 1.3972 - val_accuracy: 0.5085\n","Epoch 9/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.3718 - accuracy: 0.5099 - val_loss: 1.3965 - val_accuracy: 0.5128\n","Epoch 10/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.3412 - accuracy: 0.5208 - val_loss: 1.3523 - val_accuracy: 0.5268\n","Epoch 11/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.3102 - accuracy: 0.5309 - val_loss: 1.3301 - val_accuracy: 0.5260\n","Epoch 12/70\n","782/782 [==============================] - 8s 11ms/step - loss: 1.2867 - accuracy: 0.5415 - val_loss: 1.3098 - val_accuracy: 0.5380\n","Epoch 13/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.2618 - accuracy: 0.5524 - val_loss: 1.2856 - val_accuracy: 0.5487\n","Epoch 14/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.2387 - accuracy: 0.5632 - val_loss: 1.2553 - val_accuracy: 0.5595\n","Epoch 15/70\n","782/782 [==============================] - 8s 11ms/step - loss: 1.2178 - accuracy: 0.5690 - val_loss: 1.2157 - val_accuracy: 0.5695\n","Epoch 16/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1937 - accuracy: 0.5775 - val_loss: 1.2086 - val_accuracy: 0.5717\n","Epoch 17/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1753 - accuracy: 0.5875 - val_loss: 1.1760 - val_accuracy: 0.5832\n","Epoch 18/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1541 - accuracy: 0.5913 - val_loss: 1.2097 - val_accuracy: 0.5740\n","Epoch 19/70\n","782/782 [==============================] - 8s 11ms/step - loss: 1.1375 - accuracy: 0.5982 - val_loss: 1.1609 - val_accuracy: 0.5860\n","Epoch 20/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1206 - accuracy: 0.6054 - val_loss: 1.1410 - val_accuracy: 0.5947\n","Epoch 21/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1012 - accuracy: 0.6134 - val_loss: 1.1445 - val_accuracy: 0.5960\n","Epoch 22/70\n","782/782 [==============================] - 8s 11ms/step - loss: 1.0869 - accuracy: 0.6179 - val_loss: 1.1007 - val_accuracy: 0.6068\n","Epoch 23/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0723 - accuracy: 0.6243 - val_loss: 1.0814 - val_accuracy: 0.6210\n","Epoch 24/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0552 - accuracy: 0.6303 - val_loss: 1.0538 - val_accuracy: 0.6270\n","Epoch 25/70\n","782/782 [==============================] - 8s 11ms/step - loss: 1.0382 - accuracy: 0.6341 - val_loss: 1.0691 - val_accuracy: 0.6233\n","Epoch 26/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0248 - accuracy: 0.6403 - val_loss: 1.0494 - val_accuracy: 0.6313\n","Epoch 27/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0130 - accuracy: 0.6456 - val_loss: 1.0585 - val_accuracy: 0.6273\n","Epoch 28/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9983 - accuracy: 0.6505 - val_loss: 1.0081 - val_accuracy: 0.6410\n","Epoch 29/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9816 - accuracy: 0.6559 - val_loss: 0.9926 - val_accuracy: 0.6465\n","Epoch 30/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9710 - accuracy: 0.6615 - val_loss: 0.9727 - val_accuracy: 0.6603\n","Epoch 31/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9568 - accuracy: 0.6647 - val_loss: 0.9710 - val_accuracy: 0.6607\n","Epoch 32/70\n","782/782 [==============================] - 8s 11ms/step - loss: 0.9463 - accuracy: 0.6712 - val_loss: 0.9619 - val_accuracy: 0.6620\n","Epoch 33/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9385 - accuracy: 0.6705 - val_loss: 0.9875 - val_accuracy: 0.6515\n","Epoch 34/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9219 - accuracy: 0.6809 - val_loss: 0.9402 - val_accuracy: 0.6725\n","Epoch 35/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9127 - accuracy: 0.6828 - val_loss: 0.9849 - val_accuracy: 0.6530\n","Epoch 36/70\n","782/782 [==============================] - 8s 11ms/step - loss: 0.8997 - accuracy: 0.6859 - val_loss: 0.9142 - val_accuracy: 0.6802\n","Epoch 37/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8901 - accuracy: 0.6908 - val_loss: 0.9227 - val_accuracy: 0.6752\n","Epoch 38/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8752 - accuracy: 0.6939 - val_loss: 0.9062 - val_accuracy: 0.6860\n","Epoch 39/70\n","782/782 [==============================] - 8s 11ms/step - loss: 0.8661 - accuracy: 0.6979 - val_loss: 0.9049 - val_accuracy: 0.6805\n","Epoch 40/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8540 - accuracy: 0.7029 - val_loss: 0.8835 - val_accuracy: 0.6930\n","Epoch 41/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8457 - accuracy: 0.7056 - val_loss: 0.9116 - val_accuracy: 0.6825\n","Epoch 42/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8339 - accuracy: 0.7098 - val_loss: 0.8753 - val_accuracy: 0.6945\n","Epoch 43/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8268 - accuracy: 0.7136 - val_loss: 0.8591 - val_accuracy: 0.7003\n","Epoch 44/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8124 - accuracy: 0.7169 - val_loss: 0.8662 - val_accuracy: 0.6988\n","Epoch 45/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8023 - accuracy: 0.7190 - val_loss: 0.8544 - val_accuracy: 0.7028\n","Epoch 46/70\n","782/782 [==============================] - 8s 11ms/step - loss: 0.7959 - accuracy: 0.7225 - val_loss: 0.8443 - val_accuracy: 0.7107\n","Epoch 47/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7864 - accuracy: 0.7268 - val_loss: 0.8674 - val_accuracy: 0.7025\n","Epoch 48/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7753 - accuracy: 0.7310 - val_loss: 0.8484 - val_accuracy: 0.7057\n","Epoch 49/70\n","782/782 [==============================] - 8s 11ms/step - loss: 0.7664 - accuracy: 0.7320 - val_loss: 0.8256 - val_accuracy: 0.7190\n","Epoch 50/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7558 - accuracy: 0.7366 - val_loss: 0.8201 - val_accuracy: 0.7138\n","Epoch 51/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7492 - accuracy: 0.7414 - val_loss: 0.8302 - val_accuracy: 0.7165\n","Epoch 52/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7405 - accuracy: 0.7421 - val_loss: 0.8357 - val_accuracy: 0.7122\n","Epoch 53/70\n","782/782 [==============================] - 8s 11ms/step - loss: 0.7299 - accuracy: 0.7452 - val_loss: 0.8183 - val_accuracy: 0.7117\n","Epoch 54/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7207 - accuracy: 0.7511 - val_loss: 0.8369 - val_accuracy: 0.7155\n","Epoch 55/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7138 - accuracy: 0.7513 - val_loss: 0.8084 - val_accuracy: 0.7190\n","Epoch 56/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7033 - accuracy: 0.7553 - val_loss: 0.8096 - val_accuracy: 0.7188\n","Epoch 57/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6951 - accuracy: 0.7600 - val_loss: 0.7817 - val_accuracy: 0.7303\n","Epoch 58/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6858 - accuracy: 0.7639 - val_loss: 0.7709 - val_accuracy: 0.7315\n","Epoch 59/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6801 - accuracy: 0.7627 - val_loss: 0.7843 - val_accuracy: 0.7320\n","Epoch 60/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6731 - accuracy: 0.7645 - val_loss: 0.7779 - val_accuracy: 0.7358\n","Epoch 61/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6678 - accuracy: 0.7677 - val_loss: 0.7896 - val_accuracy: 0.7260\n","Epoch 62/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6580 - accuracy: 0.7702 - val_loss: 0.7609 - val_accuracy: 0.7345\n","Epoch 63/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6483 - accuracy: 0.7718 - val_loss: 0.7761 - val_accuracy: 0.7318\n","Epoch 64/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6411 - accuracy: 0.7779 - val_loss: 0.7650 - val_accuracy: 0.7343\n","Epoch 65/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6363 - accuracy: 0.7784 - val_loss: 0.7694 - val_accuracy: 0.7315\n","Epoch 66/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6294 - accuracy: 0.7802 - val_loss: 0.7454 - val_accuracy: 0.7362\n","Epoch 67/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6171 - accuracy: 0.7867 - val_loss: 0.7603 - val_accuracy: 0.7360\n","Epoch 68/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6104 - accuracy: 0.7891 - val_loss: 0.7402 - val_accuracy: 0.7377\n","Epoch 69/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6093 - accuracy: 0.7876 - val_loss: 0.7555 - val_accuracy: 0.7437\n","Epoch 70/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6009 - accuracy: 0.7907 - val_loss: 0.7330 - val_accuracy: 0.7395\n","Baseline 정확률은 74.69000220298767\n"]}]},{"cell_type":"code","source":["no_class = 10\n","\n","# for transfer learning only\n","from tensorflow.keras.applications import VGG16\n","\n","os.environ['PYTHONHASHSEED']=str(1)\n","tf.random.set_seed(1)\n","np.random.seed(1)\n","random.seed(1)\n","\n","# for transfer learning only\n","transfermodel = VGG16(weights='imagenet',include_top=False,\n","                    input_shape=input_shape)\n","#base_model.trainable=False     # it's up to you\n","\n","# your model architecture\n","model=Sequential()\n","# 전처리 레이어 추가/변경 가능\n","model.add(transfermodel)    # for transfer learning only\n","model.add(Flatten())        # for transfer learning only\n","model.add(Dense(1000,activation='relu')) # <<-- 변경가능\n","model.add(Dense(no_class, activation='softmax')) # <<-- activation은 변경가능\n","\n","model.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy']) # <<-- 변경가능\n","model.summary()\n","\n","hist=model.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n","             validation_data=(x_val,y_val), verbose=1)\n","\n","yours=model.evaluate(x_test,y_test,verbose=0)\n","print(\"Baseline vs yours: \",g_org_res[1]*100, yours[1]*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8AKSJ0jGkDX9","executionInfo":{"status":"ok","timestamp":1682239465285,"user_tz":-540,"elapsed":2133145,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"20e03d0c-50db-421d-e16e-e7391db40b02"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n","                                                                 \n"," flatten_2 (Flatten)         (None, 512)               0         \n","                                                                 \n"," dense_20 (Dense)            (None, 1000)              513000    \n","                                                                 \n"," dense_21 (Dense)            (None, 10)                10010     \n","                                                                 \n","=================================================================\n","Total params: 15,237,698\n","Trainable params: 15,237,698\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/70\n","782/782 [==============================] - 35s 37ms/step - loss: 0.9136 - accuracy: 0.6810 - val_loss: 0.6965 - val_accuracy: 0.7502\n","Epoch 2/70\n","782/782 [==============================] - 28s 36ms/step - loss: 0.5802 - accuracy: 0.7967 - val_loss: 0.6141 - val_accuracy: 0.7920\n","Epoch 3/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4601 - accuracy: 0.8390 - val_loss: 0.5347 - val_accuracy: 0.8140\n","Epoch 4/70\n","782/782 [==============================] - 29s 38ms/step - loss: 0.3733 - accuracy: 0.8684 - val_loss: 0.5117 - val_accuracy: 0.8220\n","Epoch 5/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2907 - accuracy: 0.8988 - val_loss: 0.5548 - val_accuracy: 0.8133\n","Epoch 6/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.2280 - accuracy: 0.9201 - val_loss: 0.5423 - val_accuracy: 0.8280\n","Epoch 7/70\n","782/782 [==============================] - 29s 38ms/step - loss: 0.1717 - accuracy: 0.9396 - val_loss: 0.5616 - val_accuracy: 0.8223\n","Epoch 8/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.1206 - accuracy: 0.9589 - val_loss: 0.5956 - val_accuracy: 0.8257\n","Epoch 9/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0844 - accuracy: 0.9708 - val_loss: 0.6667 - val_accuracy: 0.8175\n","Epoch 10/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.6344 - val_accuracy: 0.8395\n","Epoch 11/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.6354 - val_accuracy: 0.8465\n","Epoch 12/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.7598 - val_accuracy: 0.8367\n","Epoch 13/70\n","782/782 [==============================] - 29s 38ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 0.6571 - val_accuracy: 0.8432\n","Epoch 14/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.7961 - val_accuracy: 0.8400\n","Epoch 15/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.7132 - val_accuracy: 0.8438\n","Epoch 16/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.8160 - val_accuracy: 0.8443\n","Epoch 17/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.8321 - val_accuracy: 0.8440\n","Epoch 18/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.8877 - val_accuracy: 0.8345\n","Epoch 19/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.8873 - val_accuracy: 0.8340\n","Epoch 20/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.9251 - val_accuracy: 0.8413\n","Epoch 21/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.8543 - val_accuracy: 0.8273\n","Epoch 22/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.8210 - val_accuracy: 0.8465\n","Epoch 23/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.8480 - val_accuracy: 0.8470\n","Epoch 24/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.8501 - val_accuracy: 0.8407\n","Epoch 25/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.8773 - val_accuracy: 0.8325\n","Epoch 26/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.8206 - val_accuracy: 0.8450\n","Epoch 27/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.9694 - val_accuracy: 0.8378\n","Epoch 28/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.9185 - val_accuracy: 0.8505\n","Epoch 29/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.8430 - val_accuracy: 0.8480\n","Epoch 30/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.7889 - val_accuracy: 0.8438\n","Epoch 31/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.7653 - val_accuracy: 0.8438\n","Epoch 32/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.8414 - val_accuracy: 0.8438\n","Epoch 33/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.8547 - val_accuracy: 0.8428\n","Epoch 34/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.9181 - val_accuracy: 0.8388\n","Epoch 35/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.7909 - val_accuracy: 0.8450\n","Epoch 36/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.8396 - val_accuracy: 0.8388\n","Epoch 37/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.8698 - val_accuracy: 0.8300\n","Epoch 38/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.8701 - val_accuracy: 0.8472\n","Epoch 39/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.7841 - val_accuracy: 0.8465\n","Epoch 40/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.8814 - val_accuracy: 0.8475\n","Epoch 41/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.8801 - val_accuracy: 0.8472\n","Epoch 42/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.8285 - val_accuracy: 0.8512\n","Epoch 43/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.8889 - val_accuracy: 0.8388\n","Epoch 44/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.9589 - val_accuracy: 0.8393\n","Epoch 45/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.9298 - val_accuracy: 0.8435\n","Epoch 46/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.8977 - val_accuracy: 0.8468\n","Epoch 47/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.7535 - val_accuracy: 0.8490\n","Epoch 48/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.9835 - val_accuracy: 0.8367\n","Epoch 49/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.8345 - val_accuracy: 0.8537\n","Epoch 50/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.8453 - val_accuracy: 0.8453\n","Epoch 51/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.8411 - val_accuracy: 0.8475\n","Epoch 52/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.8510 - val_accuracy: 0.8505\n","Epoch 53/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.9100 - val_accuracy: 0.8478\n","Epoch 54/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.8031 - val_accuracy: 0.8572\n","Epoch 55/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.8208 - val_accuracy: 0.8478\n","Epoch 56/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.8461 - val_accuracy: 0.8453\n","Epoch 57/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.8514 - val_accuracy: 0.8390\n","Epoch 58/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.8712 - val_accuracy: 0.8438\n","Epoch 59/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.8638 - val_accuracy: 0.8438\n","Epoch 60/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.9650 - val_accuracy: 0.8380\n","Epoch 61/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.8030 - val_accuracy: 0.8565\n","Epoch 62/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.0969 - val_accuracy: 0.8300\n","Epoch 63/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.8825 - val_accuracy: 0.8500\n","Epoch 64/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.9618 - val_accuracy: 0.8320\n","Epoch 65/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.8504 - val_accuracy: 0.8480\n","Epoch 66/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.9540 - val_accuracy: 0.8455\n","Epoch 67/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.8949 - val_accuracy: 0.8480\n","Epoch 68/70\n","782/782 [==============================] - 29s 37ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.8611 - val_accuracy: 0.8472\n","Epoch 69/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.9346 - val_accuracy: 0.8418\n","Epoch 70/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.7988 - val_accuracy: 0.8568\n","Baseline vs yours:  74.69000220298767 85.33999919891357\n"]}]},{"cell_type":"code","source":["org = g_org_res[1]*100\n","yours = yours[1]*100\n","\n","if yours > (org + 2):\n","    print('SUCCESS! Difference: {0:0.3f}'.format(\n","                        (yours - org)))\n","else:\n","    print('TRY DIFFERENTLY! Difference: {0:0.3f}'.format(\n","                        (yours - org)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXOg_kk2SbeG","executionInfo":{"status":"ok","timestamp":1682239971641,"user_tz":-540,"elapsed":274,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"cd38c19c-47dd-4954-b9f7-1f7eb520ec95"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["SUCCESS! Difference: 10.650\n"]}]}]}