{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eO_bVRH4vphHi6V4Oap3ioPYBzDTOQsS","timestamp":1678969871390}],"authorship_tag":"ABX9TyOdlrBWdRW6hdTczBvIkWEI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["seed = 42\n","gamma = 0.99\n","mac-steps_per_episode = 10000\n","env = gym.make(\"CartPole-v0\")\n","env.seed(seed)\n","eps = np.finfo(np.float32).eps.item()"],"metadata":{"id":"SkwrqqK3PuJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_inputs = 4\n","num_actions = 2\n","num_hidden = 128\n","\n","inputs = layers.Input(shape = (num_inputs,))\n","common = layers.Dense(num_hidden, activation = \"relu\")(inputs)\n","action = layers.DEnse(num_actions, activation = \"softmax\")(common)\n","critic = layers.Dense(1)(common)\n","\n","model = keras.Model(inputs = inputs, output = [action, critic])"],"metadata":{"id":"TD7eYwErQFvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["while True:\n","  state = env.reset()\n","  episode_reward = 0\n","  with tf.GradientTape() as tape:\n","    for timestep in range(1, max_steps_per_episode):\n","      state = tf.convert_to_tensor(state)\n","      state = tf.expand_dims(state, 0)\n","\n","      action_probs, critic_value = model(state)\n","      critic-value_history.append(critic_value[0, 0])\n","\n","      action = np.random.choice(num_actions, p = np.squeeze(action_probs))\n","      action_probs_history.append(tf.math.log(action_probs[0, action]))\n","\n","      # Apply the sampeled action in our environment\n","      state, reward, done, _ = env.step(action)\n","      rewards_history.append(reward)\n","      episode_reward += reward\n","\n","      if done:\n","        break\n","\n","      runnung_reward = 0,05 * episode_reward + (1 - 0.05) * running_reward\n","\n","      returns = []\n","      discounted_sum = 0\n","      for r in rewards_history[::-1]:\n","        disconnected_sum = r + gamma * discounted_sum\n","        returns.insert(0, discounted_sum)\n","\n","      returns = np.array(returns)\n","      returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n","      returns = returns.tolist()\n","\n","      history = zip(action_probs_history, critic_value_history, returns)\n","      actor_losses = []\n","      critic_losses = []\n","      for log_prob, value, ret in history:\n","        diff = ret - value\n","        actor_losses.append(-log_prob * diff)\n","\n","        critic_losses.append(\n","            huber_loss(tf.expand_dims(value, 0), tf.expand_dims(ret, 0))\n","        )\n","\n","      loss_value = sum(actor_losses) + sum(critic_losses)\n","      grads = tape.gradient(loss_value, model.trainable_variables)\n","      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","      action_probs_history.clear()\n","      critic_value_history.clear()\n","      rewards_history.clear()\n","\n","    episode_count += 1\n","    if episode_count % 10 == 0:\n","      template = \"running reward: {:.2f} at episode {}\"\n","      print(template.format(running_reward, episode_cout))\n","\n","    if running_reward > 150:\n","      print(\"Solved at episode {}!\".format(episode_count))\n","      break"],"metadata":{"id":"8S8V4BAWQv6P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------"],"metadata":{"id":"Kvms56vUathz"}},{"cell_type":"code","source":["!pip install tesorflow == 2.3.0\n","!pip install gym\n","!pip install keras\n","!pip install keras-rl2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haKObz_gbHB3","executionInfo":{"status":"ok","timestamp":1683114209075,"user_tz":-540,"elapsed":11896,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"fc36bd88-b5f2-47b8-c649-427881be644b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-rl2\n","  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-rl2) (2.12.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.20.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.12.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.54.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (67.7.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.4.8)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.1)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.12.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (16.0.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->keras-rl2) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->keras-rl2) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.17.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4.3)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.3.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.7.0)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.0.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.8.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.27.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (1.26.15)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-rl2) (3.2.2)\n","Installing collected packages: keras-rl2\n","Successfully installed keras-rl2-1.0.5\n"]}]},{"cell_type":"code","source":["!pip install pygame \n","\n","import os\n","os.environ['SDL_VIDEODRIVER']='dummy'\n","import pygame\n","pygame.display.set_mode((640,480))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBdLylz6db7-","executionInfo":{"status":"ok","timestamp":1683114812808,"user_tz":-540,"elapsed":4319,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"9a00e8fc-945d-495a-9fe3-03d9f34e2acb"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (2.3.0)\n"]},{"output_type":"execute_result","data":{"text/plain":["<Surface(640x480x32 SW)>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import gym\n","import random"],"metadata":{"id":"iBURkDxAajN8","executionInfo":{"status":"ok","timestamp":1683114817377,"user_tz":-540,"elapsed":1,"user":{"displayName":"신성한","userId":"02352508022902564974"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["env = gym.make('CartPole-v0')\n","states = env.observation_space.shape[0]\n","actions = env.action_space.n"],"metadata":{"id":"aWYif-RlaqEH","executionInfo":{"status":"ok","timestamp":1683114821574,"user_tz":-540,"elapsed":274,"user":{"displayName":"신성한","userId":"02352508022902564974"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["states"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sD1Z0Rkuaq7G","executionInfo":{"status":"ok","timestamp":1683114823574,"user_tz":-540,"elapsed":4,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"f26a802b-6c6a-4e5f-ac1b-a09b7a71b292"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["actions\n","# left or right"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBzTYdUNas0d","executionInfo":{"status":"ok","timestamp":1683114825296,"user_tz":-540,"elapsed":3,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"6a935ac2-610a-4426-84c0-223f4dc60ea3"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["episodes = 10\n","for episode in range(1, episodes+1):\n","    state = env.reset()\n","    # env.reset(): Step을 실행하다가 epsiode가 끝나서 이를 초기화해서 재시작해야할 때, 초기 State를 반환\n","    # 새로운 에피소드(initial environment)를 불러온다.(reset)\n","    done = False\n","    score = 0\n","    \n","    while not done:\n","        env.render()\n","        # env.render(): Graphic User Interface (GUI)로 현재 진행상황을 출력하는 함수\n","        # 행동(action)을 취하기 이전에 환경에 대해 얻은 관찰값(observation)적용하여 그린다.\n","        action = random.choice([0, 1])\n","        # random.choice([0, 1]): 0과 1중 하나를 랜덤으로 뽑아준다.\n","        n_state, reward, done, info = env.step(action)\n","        # env.step(): 행동(action)을 취하기 이후에 환경에 대해 얻은 관찰값(observation)적용하여 제어\n","        score += reward\n","    print('Episode:{} Score:{}'.format(episode, score))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YHeoY2ETa1ga","executionInfo":{"status":"ok","timestamp":1683114831691,"user_tz":-540,"elapsed":5237,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"0cc5da01-b8a0-46be-ed0d-304ffe3e7437"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode:1 Score:27.0\n","Episode:2 Score:15.0\n","Episode:3 Score:35.0\n","Episode:4 Score:11.0\n","Episode:5 Score:24.0\n","Episode:6 Score:24.0\n","Episode:7 Score:20.0\n","Episode:8 Score:18.0\n","Episode:9 Score:32.0\n","Episode:10 Score:18.0\n"]}]},{"cell_type":"code","source":["\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","# Dense: fully connected layer 모듈\n","# Dense(8, input_dim=4, init='uniform', activation='relu')) = (출력 뉴런수, 입력뉴런수, 가중치 초기화방법, 활성화 함수)\n","# Flatten: 추출된 주요 특징을 fully connected layer에 전달하기 위해 1차원 자료로 바꿔주는 layer\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"98T-Eyi3a2WT","executionInfo":{"status":"ok","timestamp":1683114840535,"user_tz":-540,"elapsed":1,"user":{"displayName":"신성한","userId":"02352508022902564974"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def build_model(states, actions):\n","    model = Sequential()\n","    model.add(Flatten(input_shape = (1, states)))\n","    model.add(Dense(24, activation = 'relu'))\n","    # 출력 뉴런수 24개, 활성화 함수 'relu'\n","    model.add(Dense(24, activation = 'relu'))\n","    model.add(Dense(actions, activation = 'linear'))\n","    \n","    return model"],"metadata":{"id":"SRyPYGqMbygG","executionInfo":{"status":"ok","timestamp":1683114842534,"user_tz":-540,"elapsed":1,"user":{"displayName":"신성한","userId":"02352508022902564974"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["model = build_model(states, actions)"],"metadata":{"id":"tAf5z3M9byjf","executionInfo":{"status":"ok","timestamp":1683114846409,"user_tz":-540,"elapsed":1,"user":{"displayName":"신성한","userId":"02352508022902564974"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYgJ8nOLbymG","executionInfo":{"status":"ok","timestamp":1683114847771,"user_tz":-540,"elapsed":3,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"c3c07c10-79ab-47bc-d912-1fc12a270cad"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 4)                 0         \n","                                                                 \n"," dense (Dense)               (None, 24)                120       \n","                                                                 \n"," dense_1 (Dense)             (None, 24)                600       \n","                                                                 \n"," dense_2 (Dense)             (None, 2)                 50        \n","                                                                 \n","=================================================================\n","Total params: 770\n","Trainable params: 770\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from rl.agents import DQNAgent\n","from rl.policy import BoltzmannQPolicy\n","from rl.memory import SequentialMemory"],"metadata":{"id":"XOaF0CW9byot","executionInfo":{"status":"ok","timestamp":1683114851302,"user_tz":-540,"elapsed":251,"user":{"displayName":"신성한","userId":"02352508022902564974"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def build_agent(model, actions):\n","    policy = BoltzmannQPolicy()\n","    memory = SequentialMemory(limit = 10000, window_length = 1)\n","    dqn = DQNAgent(model = model, memory = memory, policy = policy, \n","                   nb_actions = actions, nb_steps_warmup = 10, target_model_update = 1e-2)\n","    \n","    return dqn\n","\n","# rl.agents.dqn.DQNAgent(model, policy=None, test_policy=None, enable_double_dqn=True, enable_dueling_network=False, dueling_type='avg')\n","# nb_steps(integer): Number of training steps to be performed.\n","# nb_steps_warmup: some schemes where the learning rate changes in a pre-determined way, to protect your oscillate parameters in the first time.\n","# target_model_update: 얼마나 자주 target model을 업데이트 할것인지(>1=업데이트를 많이, <1=업데이트를 적게)"],"metadata":{"id":"VbEp54Khb7G0","executionInfo":{"status":"ok","timestamp":1683114852705,"user_tz":-540,"elapsed":1,"user":{"displayName":"신성한","userId":"02352508022902564974"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["dqn = build_agent(model, actions)\n","dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n","dqn.fit(env, nb_steps=10000, visualize=False, verbose=1)\n","\n","# compile(self, optimizer, metrics=[])/ mae(mean absolute error)\n","# fit(self, env, nb_steps, action_repetition=1, callbacks=None, verbose=1, visualize=False, nb_max_start_steps=0, start_step_policy=None, log_interval=10000, nb_max_episode_steps=None)\n","# verbose: By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"XQK0ACh4b7JJ","executionInfo":{"status":"error","timestamp":1683114857183,"user_tz":-540,"elapsed":2259,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"89e4177d-ec02-458d-ddfd-ecc0f8c72ffd"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-19172f3910b3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# compile(self, optimizer, metrics=[])/ mae(mean absolute error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rl/agents/dqn.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, metrics)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# We use the `AdditionalUpdatesOptimizer` to efficiently soft-update the target model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_soft_target_model_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdditionalUpdatesOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclipped_masked_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rl/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, optimizer, additional_updates)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAdditionalUpdatesOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madditional_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute '_name'"]}]},{"cell_type":"code","source":["scores = dqn.test(env, nb_episodes = 10, visualize = False)\n","print(np.mean(scores.history['episode_reward']))"],"metadata":{"id":"7w9aD7nEb7Lh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = dqn.test(env, nb_episodes = 10, visualize = True)"],"metadata":{"id":"1fkpB6Itb7Nn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_ = dqn.test(env, nb_episodes = 10, visualize = True)"],"metadata":{"id":"WHkG8nAWb7QL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dqn.save_weights('dqn_weights.h5f', overwrite = True)\n","# weight값들을 저장"],"metadata":{"id":"uFublY8gb7SR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["del model\n","del dqn\n","del env"],"metadata":{"id":"0bQ8U-lsb7UX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["env = gym.make('CartPole-v0')\n","actions = env.action_space.n\n","states = env.observation_space.shape[0]\n","model = build_model(states, actions)\n","dqn = build_agent(model, actions)\n","dqn.compile(Adam(lr=1e-3), metrics=['mae'])"],"metadata":{"id":"VTQGZcGvb7Ws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dqn.load_weights('dqn_weights.h5f')"],"metadata":{"id":"3vNu93ZXb7Y2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_ = dqn.test(env, nb_episodes = 10, visualize = True)"],"metadata":{"id":"pio4_8b1cPeI"},"execution_count":null,"outputs":[]}]}