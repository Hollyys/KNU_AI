{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eO_bVRH4vphHi6V4Oap3ioPYBzDTOQsS","timestamp":1678969871390}],"authorship_tag":"ABX9TyOgNYbfp7Y8iR7ynddHtwpB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"과제5 CNN기반 영상분류문제\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1Py2GvZc1GwqNbrR4fuQrHFy6zBEdF1xF\n","\"\"\"\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten,Dense\n","from tensorflow.keras.optimizers import Adam\n","import os\n","from tensorflow.keras.datasets import cifar10\n","from sklearn.model_selection import train_test_split\n","import random\n","\n","(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n","x_train=x_train.astype(np.float32)/255.0\n","y_train=tf.keras.utils.to_categorical(y_train,10)\n","\n","x_test=x_test.astype(np.float32)/255.0\n","y_test=tf.keras.utils.to_categorical(y_test,10)\n","\n","x_val, _, y_val,_ = train_test_split(x_test, y_test, test_size=0.6, random_state=1)\n","\n","input_shape = x_train.shape[1:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPjAtRIRjtgw","executionInfo":{"status":"ok","timestamp":1683041388248,"user_tz":-540,"elapsed":12627,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"beaeb71a-a2ad-4c7e-9fa7-c6d146e57b52"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 5s 0us/step\n"]}]},{"cell_type":"code","source":["#동일조건 유지해야 하는 변수(두 모델 모두 동일하게 적용해야 함)\n","g_epoch = 70\n","g_batch = 64\n","\n","#중요 : 아래함수 변경 불가!\n","def reset_random_seeds():\n","   os.environ['PYTHONHASHSEED']=str(1)\n","   tf.random.set_seed(1)\n","   np.random.seed(1)\n","   random.seed(1)\n","   os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","\n","reset_random_seeds() #필수\n","   \n","print(\"reduced train/val size:\", len(x_train), len(x_val), \"input shape:\", input_shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCxhnS9dj5K1","executionInfo":{"status":"ok","timestamp":1683041391136,"user_tz":-540,"elapsed":343,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"1cfc5ae1-3683-4b9f-a34a-377ccf39e041"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["reduced train/val size: 50000 4000 input shape: (32, 32, 3)\n"]}]},{"cell_type":"code","source":["# to make this notebook's output stable across runs\n","\n","tf.__version__\n","\n","from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n","\n","cnn=Sequential()\n","cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)))\n","cnn.add(MaxPooling2D(pool_size=(2,2)))\n","cnn.add(Dropout(0.25))\n","cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2,2)))\n","cnn.add(Dropout(0.25))\n","cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n","cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n","cnn.add(MaxPooling2D(pool_size=(2,2)))\n","cnn.add(Flatten())\n","cnn.add(Dense(1000,activation='relu'))\n","cnn.add(Dropout(0.5))\n","cnn.add(Dense(10,activation='softmax'))\n","\n","cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n","cnn.summary()\n","\n","hist=cnn.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n","             validation_data=(x_val,y_val), verbose=1)\n","\n","g_org_res=cnn.evaluate(x_test,y_test,verbose=0)\n","print(\"Baseline 정확률은\",g_org_res[1]*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hiodoNBzj90x","executionInfo":{"status":"ok","timestamp":1683042032667,"user_tz":-540,"elapsed":639125,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"3a52eda9-ee8d-4b40-ebd2-391637daecf7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 15, 15, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 15, 15, 128)       73856     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 7, 7, 256)         295168    \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 7, 7, 256)         590080    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 2304)              0         \n","                                                                 \n"," dense (Dense)               (None, 1000)              2305000   \n","                                                                 \n"," dropout_2 (Dropout)         (None, 1000)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                10010     \n","                                                                 \n","=================================================================\n","Total params: 3,275,906\n","Trainable params: 3,275,906\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/70\n","782/782 [==============================] - 21s 12ms/step - loss: 2.0938 - accuracy: 0.2179 - val_loss: 1.8530 - val_accuracy: 0.3370\n","Epoch 2/70\n","782/782 [==============================] - 8s 11ms/step - loss: 1.7561 - accuracy: 0.3529 - val_loss: 1.6722 - val_accuracy: 0.3940\n","Epoch 3/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.6315 - accuracy: 0.3987 - val_loss: 1.5728 - val_accuracy: 0.4218\n","Epoch 4/70\n","782/782 [==============================] - 9s 12ms/step - loss: 1.5479 - accuracy: 0.4335 - val_loss: 1.5477 - val_accuracy: 0.4433\n","Epoch 5/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.4947 - accuracy: 0.4535 - val_loss: 1.4711 - val_accuracy: 0.4778\n","Epoch 6/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.4470 - accuracy: 0.4740 - val_loss: 1.4433 - val_accuracy: 0.4897\n","Epoch 7/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.4080 - accuracy: 0.4900 - val_loss: 1.4134 - val_accuracy: 0.4983\n","Epoch 8/70\n","782/782 [==============================] - 9s 12ms/step - loss: 1.3748 - accuracy: 0.5046 - val_loss: 1.3629 - val_accuracy: 0.5153\n","Epoch 9/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.3443 - accuracy: 0.5184 - val_loss: 1.3474 - val_accuracy: 0.5250\n","Epoch 10/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.3181 - accuracy: 0.5290 - val_loss: 1.3135 - val_accuracy: 0.5372\n","Epoch 11/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.2895 - accuracy: 0.5384 - val_loss: 1.2757 - val_accuracy: 0.5420\n","Epoch 12/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.2644 - accuracy: 0.5501 - val_loss: 1.2420 - val_accuracy: 0.5575\n","Epoch 13/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.2420 - accuracy: 0.5613 - val_loss: 1.2325 - val_accuracy: 0.5625\n","Epoch 14/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.2213 - accuracy: 0.5696 - val_loss: 1.2099 - val_accuracy: 0.5688\n","Epoch 15/70\n","782/782 [==============================] - 9s 12ms/step - loss: 1.2014 - accuracy: 0.5734 - val_loss: 1.1753 - val_accuracy: 0.5850\n","Epoch 16/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1783 - accuracy: 0.5847 - val_loss: 1.1494 - val_accuracy: 0.5910\n","Epoch 17/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1601 - accuracy: 0.5897 - val_loss: 1.1485 - val_accuracy: 0.5955\n","Epoch 18/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1423 - accuracy: 0.5980 - val_loss: 1.1361 - val_accuracy: 0.5985\n","Epoch 19/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1221 - accuracy: 0.6050 - val_loss: 1.1049 - val_accuracy: 0.6080\n","Epoch 20/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.1044 - accuracy: 0.6128 - val_loss: 1.0767 - val_accuracy: 0.6227\n","Epoch 21/70\n","782/782 [==============================] - 9s 12ms/step - loss: 1.0830 - accuracy: 0.6198 - val_loss: 1.0848 - val_accuracy: 0.6155\n","Epoch 22/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0693 - accuracy: 0.6243 - val_loss: 1.0413 - val_accuracy: 0.6390\n","Epoch 23/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0558 - accuracy: 0.6299 - val_loss: 1.0263 - val_accuracy: 0.6420\n","Epoch 24/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0362 - accuracy: 0.6377 - val_loss: 1.0121 - val_accuracy: 0.6503\n","Epoch 25/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0223 - accuracy: 0.6410 - val_loss: 1.0099 - val_accuracy: 0.6423\n","Epoch 26/70\n","782/782 [==============================] - 9s 11ms/step - loss: 1.0083 - accuracy: 0.6463 - val_loss: 0.9901 - val_accuracy: 0.6475\n","Epoch 27/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9938 - accuracy: 0.6510 - val_loss: 0.9812 - val_accuracy: 0.6555\n","Epoch 28/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9761 - accuracy: 0.6573 - val_loss: 0.9569 - val_accuracy: 0.6578\n","Epoch 29/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9637 - accuracy: 0.6613 - val_loss: 0.9590 - val_accuracy: 0.6578\n","Epoch 30/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9505 - accuracy: 0.6677 - val_loss: 0.9365 - val_accuracy: 0.6708\n","Epoch 31/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9320 - accuracy: 0.6735 - val_loss: 0.9296 - val_accuracy: 0.6715\n","Epoch 32/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9243 - accuracy: 0.6762 - val_loss: 0.9263 - val_accuracy: 0.6743\n","Epoch 33/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9107 - accuracy: 0.6815 - val_loss: 0.9229 - val_accuracy: 0.6727\n","Epoch 34/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.9026 - accuracy: 0.6842 - val_loss: 0.9038 - val_accuracy: 0.6852\n","Epoch 35/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8885 - accuracy: 0.6915 - val_loss: 0.9073 - val_accuracy: 0.6780\n","Epoch 36/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8779 - accuracy: 0.6926 - val_loss: 0.8806 - val_accuracy: 0.6877\n","Epoch 37/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8662 - accuracy: 0.6992 - val_loss: 0.8773 - val_accuracy: 0.6895\n","Epoch 38/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8559 - accuracy: 0.7012 - val_loss: 0.8716 - val_accuracy: 0.6963\n","Epoch 39/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8464 - accuracy: 0.7050 - val_loss: 0.8575 - val_accuracy: 0.6948\n","Epoch 40/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8341 - accuracy: 0.7094 - val_loss: 0.8384 - val_accuracy: 0.7070\n","Epoch 41/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8267 - accuracy: 0.7124 - val_loss: 0.8581 - val_accuracy: 0.7005\n","Epoch 42/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8108 - accuracy: 0.7180 - val_loss: 0.8295 - val_accuracy: 0.7107\n","Epoch 43/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.8058 - accuracy: 0.7193 - val_loss: 0.8211 - val_accuracy: 0.7143\n","Epoch 44/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7922 - accuracy: 0.7259 - val_loss: 0.8202 - val_accuracy: 0.7107\n","Epoch 45/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7863 - accuracy: 0.7256 - val_loss: 0.8167 - val_accuracy: 0.7048\n","Epoch 46/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7756 - accuracy: 0.7279 - val_loss: 0.8064 - val_accuracy: 0.7150\n","Epoch 47/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7719 - accuracy: 0.7320 - val_loss: 0.8078 - val_accuracy: 0.7160\n","Epoch 48/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7581 - accuracy: 0.7354 - val_loss: 0.7899 - val_accuracy: 0.7185\n","Epoch 49/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7460 - accuracy: 0.7390 - val_loss: 0.7788 - val_accuracy: 0.7207\n","Epoch 50/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7374 - accuracy: 0.7436 - val_loss: 0.7824 - val_accuracy: 0.7228\n","Epoch 51/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7301 - accuracy: 0.7457 - val_loss: 0.7814 - val_accuracy: 0.7245\n","Epoch 52/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7236 - accuracy: 0.7485 - val_loss: 0.7856 - val_accuracy: 0.7212\n","Epoch 53/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7130 - accuracy: 0.7534 - val_loss: 0.7672 - val_accuracy: 0.7275\n","Epoch 54/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.7077 - accuracy: 0.7543 - val_loss: 0.7861 - val_accuracy: 0.7230\n","Epoch 55/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6998 - accuracy: 0.7584 - val_loss: 0.7541 - val_accuracy: 0.7368\n","Epoch 56/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6940 - accuracy: 0.7586 - val_loss: 0.7655 - val_accuracy: 0.7320\n","Epoch 57/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6840 - accuracy: 0.7602 - val_loss: 0.7510 - val_accuracy: 0.7345\n","Epoch 58/70\n","782/782 [==============================] - 9s 12ms/step - loss: 0.6742 - accuracy: 0.7653 - val_loss: 0.7392 - val_accuracy: 0.7333\n","Epoch 59/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6654 - accuracy: 0.7676 - val_loss: 0.7400 - val_accuracy: 0.7345\n","Epoch 60/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6587 - accuracy: 0.7727 - val_loss: 0.7444 - val_accuracy: 0.7393\n","Epoch 61/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6548 - accuracy: 0.7724 - val_loss: 0.7379 - val_accuracy: 0.7402\n","Epoch 62/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6467 - accuracy: 0.7750 - val_loss: 0.7246 - val_accuracy: 0.7393\n","Epoch 63/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6368 - accuracy: 0.7787 - val_loss: 0.7282 - val_accuracy: 0.7433\n","Epoch 64/70\n","782/782 [==============================] - 9s 12ms/step - loss: 0.6284 - accuracy: 0.7822 - val_loss: 0.7161 - val_accuracy: 0.7498\n","Epoch 65/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6221 - accuracy: 0.7834 - val_loss: 0.7336 - val_accuracy: 0.7430\n","Epoch 66/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6132 - accuracy: 0.7890 - val_loss: 0.7062 - val_accuracy: 0.7513\n","Epoch 67/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6062 - accuracy: 0.7898 - val_loss: 0.7113 - val_accuracy: 0.7470\n","Epoch 68/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.6014 - accuracy: 0.7922 - val_loss: 0.7096 - val_accuracy: 0.7505\n","Epoch 69/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.5953 - accuracy: 0.7942 - val_loss: 0.7008 - val_accuracy: 0.7558\n","Epoch 70/70\n","782/782 [==============================] - 9s 11ms/step - loss: 0.5862 - accuracy: 0.7976 - val_loss: 0.6992 - val_accuracy: 0.7495\n","Baseline 정확률은 75.30999779701233\n"]}]},{"cell_type":"code","source":["no_class = 10\n","\n","# for transfer learning only\n","from tensorflow.keras.applications import VGG16\n","\n","os.environ['PYTHONHASHSEED']=str(1)\n","tf.random.set_seed(1)\n","np.random.seed(1)\n","random.seed(1)\n","\n","# for transfer learning only\n","transfermodel = VGG16(weights='imagenet',include_top=False,\n","                    input_shape=input_shape)\n","#base_model.trainable=False     # it's up to you\n","\n","# your model architecture\n","model=Sequential()\n","# 전처리 레이어 추가/변경 가능\n","model.add(transfermodel)    # for transfer learning only\n","model.add(Flatten())        # for transfer learning only\n","model.add(Dense(1000,activation='relu')) # <<-- 변경가능\n","model.add(Dense(no_class, activation='softmax')) # <<-- activation은 변경가능\n","\n","model.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy']) # <<-- 변경가능\n","model.summary()\n","\n","hist=model.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n","             validation_data=(x_val,y_val), verbose=1)\n","\n","yours=model.evaluate(x_test,y_test,verbose=0)\n","print(\"Baseline vs yours: \",g_org_res[1]*100, yours[1]*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8AKSJ0jGkDX9","executionInfo":{"status":"ok","timestamp":1683044865755,"user_tz":-540,"elapsed":2189872,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"833a23b7-b3f4-414f-cf67-9473b610beb2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n","                                                                 \n"," flatten_1 (Flatten)         (None, 512)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1000)              513000    \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                10010     \n","                                                                 \n","=================================================================\n","Total params: 15,237,698\n","Trainable params: 15,237,698\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/70\n","782/782 [==============================] - 36s 40ms/step - loss: 0.9136 - accuracy: 0.6810 - val_loss: 0.6965 - val_accuracy: 0.7502\n","Epoch 2/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.5802 - accuracy: 0.7967 - val_loss: 0.6141 - val_accuracy: 0.7920\n","Epoch 3/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.4601 - accuracy: 0.8390 - val_loss: 0.5347 - val_accuracy: 0.8140\n","Epoch 4/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.3733 - accuracy: 0.8684 - val_loss: 0.5117 - val_accuracy: 0.8220\n","Epoch 5/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.2907 - accuracy: 0.8988 - val_loss: 0.5548 - val_accuracy: 0.8133\n","Epoch 6/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.2280 - accuracy: 0.9201 - val_loss: 0.5423 - val_accuracy: 0.8280\n","Epoch 7/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.1717 - accuracy: 0.9396 - val_loss: 0.5616 - val_accuracy: 0.8223\n","Epoch 8/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.1206 - accuracy: 0.9589 - val_loss: 0.5956 - val_accuracy: 0.8257\n","Epoch 9/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0844 - accuracy: 0.9708 - val_loss: 0.6667 - val_accuracy: 0.8175\n","Epoch 10/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.6344 - val_accuracy: 0.8395\n","Epoch 11/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.6354 - val_accuracy: 0.8465\n","Epoch 12/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 0.7598 - val_accuracy: 0.8367\n","Epoch 13/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0410 - accuracy: 0.9860 - val_loss: 0.6571 - val_accuracy: 0.8432\n","Epoch 14/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0346 - accuracy: 0.9887 - val_loss: 0.7961 - val_accuracy: 0.8400\n","Epoch 15/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.7132 - val_accuracy: 0.8438\n","Epoch 16/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0282 - accuracy: 0.9903 - val_loss: 0.8160 - val_accuracy: 0.8443\n","Epoch 17/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.8321 - val_accuracy: 0.8440\n","Epoch 18/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.8877 - val_accuracy: 0.8345\n","Epoch 19/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.8873 - val_accuracy: 0.8340\n","Epoch 20/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.9251 - val_accuracy: 0.8413\n","Epoch 21/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 0.8543 - val_accuracy: 0.8273\n","Epoch 22/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.8210 - val_accuracy: 0.8465\n","Epoch 23/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.8480 - val_accuracy: 0.8470\n","Epoch 24/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.8501 - val_accuracy: 0.8407\n","Epoch 25/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.8773 - val_accuracy: 0.8325\n","Epoch 26/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.8206 - val_accuracy: 0.8450\n","Epoch 27/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.9694 - val_accuracy: 0.8378\n","Epoch 28/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.9185 - val_accuracy: 0.8505\n","Epoch 29/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.8430 - val_accuracy: 0.8480\n","Epoch 30/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.7889 - val_accuracy: 0.8438\n","Epoch 31/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.7653 - val_accuracy: 0.8438\n","Epoch 32/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.8414 - val_accuracy: 0.8438\n","Epoch 33/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.8547 - val_accuracy: 0.8428\n","Epoch 34/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.9181 - val_accuracy: 0.8388\n","Epoch 35/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 0.7909 - val_accuracy: 0.8450\n","Epoch 36/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.8396 - val_accuracy: 0.8388\n","Epoch 37/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.8698 - val_accuracy: 0.8300\n","Epoch 38/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.8701 - val_accuracy: 0.8472\n","Epoch 39/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.7841 - val_accuracy: 0.8465\n","Epoch 40/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.8814 - val_accuracy: 0.8475\n","Epoch 41/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.8801 - val_accuracy: 0.8472\n","Epoch 42/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.8285 - val_accuracy: 0.8512\n","Epoch 43/70\n","782/782 [==============================] - 30s 38ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.8889 - val_accuracy: 0.8388\n","Epoch 44/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.9589 - val_accuracy: 0.8393\n","Epoch 45/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.9298 - val_accuracy: 0.8435\n","Epoch 46/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.8977 - val_accuracy: 0.8468\n","Epoch 47/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.7535 - val_accuracy: 0.8490\n","Epoch 48/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.9835 - val_accuracy: 0.8367\n","Epoch 49/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.8345 - val_accuracy: 0.8537\n","Epoch 50/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.8453 - val_accuracy: 0.8453\n","Epoch 51/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.8411 - val_accuracy: 0.8475\n","Epoch 52/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.8510 - val_accuracy: 0.8505\n","Epoch 53/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.9100 - val_accuracy: 0.8478\n","Epoch 54/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.8031 - val_accuracy: 0.8572\n","Epoch 55/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.8208 - val_accuracy: 0.8478\n","Epoch 56/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.8461 - val_accuracy: 0.8453\n","Epoch 57/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.8514 - val_accuracy: 0.8390\n","Epoch 58/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.8712 - val_accuracy: 0.8438\n","Epoch 59/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.8638 - val_accuracy: 0.8438\n","Epoch 60/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.9650 - val_accuracy: 0.8380\n","Epoch 61/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.8030 - val_accuracy: 0.8565\n","Epoch 62/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.0969 - val_accuracy: 0.8300\n","Epoch 63/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.8825 - val_accuracy: 0.8500\n","Epoch 64/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.9618 - val_accuracy: 0.8320\n","Epoch 65/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.8504 - val_accuracy: 0.8480\n","Epoch 66/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.9540 - val_accuracy: 0.8455\n","Epoch 67/70\n","782/782 [==============================] - 30s 39ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.8949 - val_accuracy: 0.8480\n","Epoch 68/70\n","782/782 [==============================] - 31s 39ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.8611 - val_accuracy: 0.8472\n","Epoch 69/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.9346 - val_accuracy: 0.8418\n","Epoch 70/70\n","782/782 [==============================] - 31s 40ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.7988 - val_accuracy: 0.8568\n","Baseline vs yours:  75.30999779701233 85.33999919891357\n"]}]},{"cell_type":"code","source":["org = g_org_res[1]*100\n","yours = yours[1]*100\n","\n","if yours > (org + 2):\n","    print('SUCCESS! Difference: {0:0.3f}'.format(\n","                        (yours - org)))\n","else:\n","    print('TRY DIFFERENTLY! Difference: {0:0.3f}'.format(\n","                        (yours - org)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AXOg_kk2SbeG","executionInfo":{"status":"ok","timestamp":1683044877698,"user_tz":-540,"elapsed":301,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"10ede756-adb3-4b5c-9cbc-1c985c9e06ea"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["SUCCESS! Difference: 10.030\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Save the Predict File\n","submission = pd.read_csv('Assignmnet_4_sample_solution.csv')\n","\n","# 최종 제출 모델에 예측을 함.\n","y_predict = model.predict(x_test)\n","\n","submission['label'] = np.argmax(y_predict,axis = 1)\n","submission.to_csv('submission.csv',index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_HG8I5UEscF","executionInfo":{"status":"ok","timestamp":1683044920882,"user_tz":-540,"elapsed":4582,"user":{"displayName":"신성한","userId":"02352508022902564974"}},"outputId":"d30251f0-a114-4d04-8194-de63a341d31d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 3s 7ms/step\n"]}]}]}